{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9383dc0e",
   "metadata": {},
   "source": [
    "## Data Exploration and Enrichment Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b660f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Task 1: Data Exploration and Enrichment\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD AND EXPLORE DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load main dataset\n",
    "df = pd.read_csv('../_data/_raw/ethiopia_fi_unified_data.csv')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Load reference codes\n",
    "ref_codes = pd.read_csv('../_data/_raw/reference_codes.csv')\n",
    "print(\"\\nReference codes shape:\", ref_codes.shape)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. UNDERSTAND THE SCHEMA\n",
    "# ============================================================================\n",
    "\n",
    "# Check record types\n",
    "print(\"\\n=== Record Type Distribution ===\")\n",
    "record_type_counts = df['record_type'].value_counts()\n",
    "print(record_type_counts)\n",
    "\n",
    "# Check pillars\n",
    "print(\"\\n=== Pillar Distribution ===\")\n",
    "pillar_counts = df['pillar'].value_counts(dropna=False)\n",
    "print(pillar_counts)\n",
    "\n",
    "# Check source types\n",
    "print(\"\\n=== Source Type Distribution ===\")\n",
    "source_counts = df['source_type'].value_counts(dropna=False)\n",
    "print(source_counts)\n",
    "\n",
    "# Check confidence levels\n",
    "print(\"\\n=== Confidence Level Distribution ===\")\n",
    "confidence_counts = df['confidence'].value_counts(dropna=False)\n",
    "print(confidence_counts)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. EXPLORE OBSERVATIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Filter observations only\n",
    "observations = df[df['record_type'] == 'observation'].copy()\n",
    "observations['observation_date'] = pd.to_datetime(observations['observation_date'])\n",
    "\n",
    "print(f\"\\nTotal observations: {len(observations)}\")\n",
    "print(f\"Date range: {observations['observation_date'].min()} to {observations['observation_date'].max()}\")\n",
    "\n",
    "# Check unique indicators\n",
    "print(\"\\n=== Unique Indicators ===\")\n",
    "unique_indicators = observations['indicator_code'].unique()\n",
    "for indicator in unique_indicators:\n",
    "    count = observations[observations['indicator_code'] == indicator].shape[0]\n",
    "    print(f\"{indicator}: {count} records\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. EXPLORE EVENTS\n",
    "# ============================================================================\n",
    "\n",
    "events = df[df['record_type'] == 'event'].copy()\n",
    "print(f\"\\nTotal events: {len(events)}\")\n",
    "print(\"\\nEvent categories:\")\n",
    "print(events['category'].value_counts())\n",
    "\n",
    "print(\"\\n=== Key Events ===\")\n",
    "key_events = events[['event_name', 'event_date', 'category', 'description']]\n",
    "print(key_events.to_string())\n",
    "\n",
    "# ============================================================================\n",
    "# 5. EXPLORE IMPACT LINKS\n",
    "# ============================================================================\n",
    "\n",
    "impact_links = df[df['record_type'] == 'impact_link'].copy()\n",
    "print(f\"\\nTotal impact links: {len(impact_links)}\")\n",
    "\n",
    "# Merge with events to see relationships\n",
    "merged_impacts = pd.merge(\n",
    "    impact_links,\n",
    "    events[['event_id', 'event_name', 'category']],\n",
    "    left_on='parent_id',\n",
    "    right_on='event_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"\\n=== Event-Impact Relationships ===\")\n",
    "for _, row in merged_impacts.iterrows():\n",
    "    print(f\"{row['event_name']} -> {row['related_indicator']}\")\n",
    "    print(f\"  Direction: {row['impact_direction']}, Magnitude: {row['impact_magnitude']}\")\n",
    "    print(f\"  Lag: {row['lag_months']} months, Evidence: {row['evidence_basis']}\")\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# 6. DATA ENRICHMENT - ADD NEW RECORDS\n",
    "# ============================================================================\n",
    "\n",
    "def create_new_record(record_type, **kwargs):\n",
    "    \"\"\"Helper function to create new records following schema\"\"\"\n",
    "    new_record = {\n",
    "        'record_id': f\"custom_{datetime.now().strftime('%Y%m%d%H%M%S')}_{np.random.randint(1000,9999)}\",\n",
    "        'record_type': record_type,\n",
    "        'created_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'created_by': 'data_scientist',\n",
    "    }\n",
    "    \n",
    "    # Add provided fields\n",
    "    for key, value in kwargs.items():\n",
    "        new_record[key] = value\n",
    "    \n",
    "    return new_record\n",
    "\n",
    "# Example: Add new observations\n",
    "new_observations = []\n",
    "\n",
    "# Example 1: 4G Coverage data (hypothetical)\n",
    "new_obs_4g = create_new_record(\n",
    "    record_type='observation',\n",
    "    pillar='enabler',\n",
    "    indicator='4G Network Coverage',\n",
    "    indicator_code='ENB_4G_COVERAGE',\n",
    "    value_numeric=45.2,  # percentage\n",
    "    value_text=None,\n",
    "    observation_date='2024-12-01',\n",
    "    source_name='GSMA Mobile Connectivity Index',\n",
    "    source_url='https://www.gsma.com/mobileconnectivityindex/',\n",
    "    source_type='report',\n",
    "    confidence='medium',\n",
    "    notes='Estimated 4G population coverage in Ethiopia, 2024'\n",
    ")\n",
    "new_observations.append(new_obs_4g)\n",
    "\n",
    "# Example 2: Smartphone penetration\n",
    "new_obs_smartphone = create_new_record(\n",
    "    record_type='observation',\n",
    "    pillar='enabler',\n",
    "    indicator='Smartphone Penetration',\n",
    "    indicator_code='ENB_SMARTPHONE_PEN',\n",
    "    value_numeric=38.7,\n",
    "    observation_date='2024-12-01',\n",
    "    source_name='GSMA Intelligence',\n",
    "    source_url='https://www.gsmaintelligence.com/',\n",
    "    source_type='report',\n",
    "    confidence='medium',\n",
    "    notes='Percentage of population with smartphones'\n",
    ")\n",
    "new_observations.append(new_obs_smartphone)\n",
    "\n",
    "# Example 3: Add a new event - Fayda Digital ID Rollout\n",
    "new_event = create_new_record(\n",
    "    record_type='event',\n",
    "    event_name='Fayda Digital ID National Rollout',\n",
    "    event_date='2025-03-15',\n",
    "    category='infrastructure',\n",
    "    description='National rollout of Fayda digital ID system, expected to boost KYC efficiency',\n",
    "    source_name='National Bank of Ethiopia',\n",
    "    source_url='https://id.gov.et/',\n",
    "    confidence='high'\n",
    ")\n",
    "new_observations.append(new_event)\n",
    "\n",
    "# Example 4: Add impact link for Fayda Digital ID\n",
    "new_impact = create_new_record(\n",
    "    record_type='impact_link',\n",
    "    parent_id=new_event['record_id'],  # Reference the event we just created\n",
    "    pillar='access',\n",
    "    related_indicator='ACC_OWNERSHIP',\n",
    "    impact_direction='positive',\n",
    "    impact_magnitude=2.5,  # Percentage point increase\n",
    "    lag_months=6,\n",
    "    evidence_basis='comparable_country',\n",
    "    evidence_description='Digital ID systems in India (Aadhaar) increased account ownership by 2-3% annually',\n",
    "    confidence='medium'\n",
    ")\n",
    "new_observations.append(new_impact)\n",
    "\n",
    "# Convert to DataFrame and append to original\n",
    "new_records_df = pd.DataFrame(new_observations)\n",
    "\n",
    "# Save enriched dataset\n",
    "enriched_df = pd.concat([df, new_records_df], ignore_index=True)\n",
    "enriched_df.to_csv('../_data/processed/ethiopia_fi_enriched.csv', index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# 7. CREATE ENRICHMENT LOG\n",
    "# ============================================================================\n",
    "\n",
    "log_entries = []\n",
    "for idx, row in new_records_df.iterrows():\n",
    "    log_entry = {\n",
    "        'record_id': row['record_id'],\n",
    "        'record_type': row['record_type'],\n",
    "        'added_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'collected_by': 'Your Name',\n",
    "        'source_url': row.get('source_url', 'N/A'),\n",
    "        'original_text': row.get('description', row.get('notes', 'N/A')),\n",
    "        'confidence': row.get('confidence', 'medium'),\n",
    "        'notes': row.get('notes', 'Why added: To improve forecasting model coverage'),\n",
    "        'usefulness': 'Provides additional context for infrastructure enablers'\n",
    "    }\n",
    "    log_entries.append(log_entry)\n",
    "\n",
    "log_df = pd.DataFrame(log_entries)\n",
    "log_df.to_markdown('../_data/processed/data_enrichment_log.md', index=False)\n",
    "\n",
    "print(f\"\\n✅ Added {len(new_records_df)} new records\")\n",
    "print(\"✅ Saved enriched dataset to: ../_data/processed/ethiopia_fi_enriched.csv\")\n",
    "print(\"✅ Created enrichment log: ../_data/processed/data_enrichment_log.md\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. VISUALIZE DATA COVERAGE\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Record type distribution\n",
    "axes[0, 0].bar(record_type_counts.index, record_type_counts.values)\n",
    "axes[0, 0].set_title('Record Type Distribution')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Confidence levels\n",
    "axes[0, 1].bar(confidence_counts.index, confidence_counts.values)\n",
    "axes[0, 1].set_title('Confidence Level Distribution')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Temporal coverage\n",
    "obs_dates = observations['observation_date'].dt.year.value_counts().sort_index()\n",
    "axes[1, 0].plot(obs_dates.index, obs_dates.values, marker='o')\n",
    "axes[1, 0].set_title('Observations by Year')\n",
    "axes[1, 0].set_xlabel('Year')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Event categories\n",
    "event_cats = events['category'].value_counts()\n",
    "axes[1, 1].pie(event_cats.values, labels=event_cats.index, autopct='%1.1f%%')\n",
    "axes[1, 1].set_title('Event Categories')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../_data/processed/data_coverage_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
